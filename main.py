import functions_framework
import csv
import os
from datetime import datetime
from google.cloud import storage
from google.cloud import bigquery
from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail

# ãƒ¡ãƒ¼ãƒ«é€ä¿¡ç”¨é–¢æ•°
def send_email(to_email, subject, content):
    message = Mail(
        from_email=os.environ.get("FROM_EMAIL"),
        to_emails=to_email,
        subject=subject,
        plain_text_content=content,
    )
    try:
        sg = SendGridAPIClient(os.environ.get("SENDGRID_API_KEY"))
        sg.send(message)
        print(f"ğŸ“§ Email sent to {to_email}")
    except Exception as e:
        print(f"SendGrid error for {to_email}: {e}")

# Cloud Function ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
@functions_framework.cloud_event
def process_csv(cloud_event):
    data = cloud_event.data
    bucket_name = data["bucket"]
    file_name = data["name"]

    print(f"ğŸ”” å—ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆ - ãƒã‚±ãƒƒãƒˆ: {bucket_name}, ãƒ•ã‚¡ã‚¤ãƒ«å: {file_name}")

    # Cloud Storage ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(file_name)
    temp_file_path = f"/tmp/{file_name}"
    blob.download_to_filename(temp_file_path)
    print(f"ğŸ“¥ ä¸€æ™‚ä¿å­˜: {temp_file_path}")

    # BigQuery ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    bq_client = bigquery.Client()
    dataset_id = "exam_dataset"
    table_id = "csv_test"
    table_ref = bq_client.dataset(dataset_id).table(table_id)

    # ç¾åœ¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    current_time = datetime.utcnow().isoformat()

    # CSV èª­ã¿è¾¼ã¿ã¨ãƒ‡ãƒ¼ã‚¿æ•´å½¢
    rows_to_insert = []
    recipients = []

    with open(temp_file_path, mode='r', encoding='utf-8', errors='replace') as file:
        reader = csv.DictReader(file)
        for row in reader:
            # ç©ºã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            if any(v.strip() == "" for v in row.values()):
                print(f"âš ï¸ ç©ºã®å€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—: {row}")
                continue

            # create_at ã‚’ç¾åœ¨ã®æ™‚åˆ»ã§è¿½åŠ ï¼ˆCSVã®å€¤ãŒã‚ã£ã¦ã‚‚ä¸Šæ›¸ãï¼‰
            row["create_at"] = current_time
            rows_to_insert.append(row)

            # ãƒ¡ãƒ¼ãƒ«é€ä¿¡å¯¾è±¡ã®æŠ½å‡º
            send_flg = row.get("send_flg", "").strip()
            email = row.get("email", "").strip()
            if email and (send_flg == "1" or send_flg == ""):
                recipients.append(email)

    # BigQuery ã«ä¿å­˜
    errors = bq_client.insert_rows_json(table_ref, rows_to_insert)
    if errors:
        print(f"âŒ BigQueryæŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
    else:
        print(f"âœ… BigQueryã« {len(rows_to_insert)} ä»¶ã‚’æ›¸ãè¾¼ã¿å®Œäº†ã€‚")

        # ãƒ¡ãƒ¼ãƒ«é€ä¿¡
        for email in recipients:
            send_email(
                to_email=email,
                subject="CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†é€šçŸ¥",
                content=f"{file_name} ã«å«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ BigQuery ã«ä¿å­˜ã—ã¾ã—ãŸã€‚"
            )
