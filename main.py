import functions_framework
import csv
import os
from google.cloud import storage
from google.cloud import bigquery
from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail
from datetime import datetime, timezone

# ãƒ¡ãƒ¼ãƒ«é€ä¿¡ç”¨é–¢æ•°ï¼ˆå®›å…ˆã¨æœ¬æ–‡ã‚’å¼•æ•°ã§å—ã‘å–ã‚‹ã‚ˆã†ä¿®æ­£ï¼‰
def send_email(to_email, subject, content):
    message = Mail(
        from_email=os.environ.get("FROM_EMAIL"),
        to_emails=to_email,
        subject=subject,
        plain_text_content=content,
    )
    try:
        sg = SendGridAPIClient(os.environ.get("SENDGRID_API_KEY"))
        sg.send(message)
        print(f"ğŸ“§ Email sent to {to_email}")
    except Exception as e:
        print(f"SendGrid error for {to_email}: {e}")

# Cloud Function æœ¬ä½“
@functions_framework.cloud_event
def process_csv(cloud_event):
    data = cloud_event.data
    bucket_name = data["bucket"]
    file_name = data["name"]

    print(f"ğŸ”” å—ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆ - ãƒã‚±ãƒƒãƒˆ: {bucket_name}, ãƒ•ã‚¡ã‚¤ãƒ«å: {file_name}")

    # Cloud Storage ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(file_name)
    temp_file_path = f"/tmp/{file_name}"
    blob.download_to_filename(temp_file_path)
    print(f"ğŸ“¥ ä¸€æ™‚ä¿å­˜: {temp_file_path}")

    # BigQuery ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    bq_client = bigquery.Client()
    dataset_id = "exam_dataset"
    table_id = "csv_test"
    table_ref = bq_client.dataset(dataset_id).table(table_id)

    # CSV èª­ã¿è¾¼ã¿ã¨ãƒ‡ãƒ¼ã‚¿æ•´å½¢
    rows_to_insert = []
    email_content_map = {}

    with open(temp_file_path, mode='r', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        for row in reader:
            # ç©ºã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            if any(v.strip() == "" for v in row.values()):
                print(f"âš ï¸ ç©ºã®å€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—: {row}")
                continue

            # create_at ã‚’ç¾åœ¨æ™‚åˆ»ã§è¿½åŠ ï¼ˆUTCï¼‰
            row["create_at"] = datetime.now(timezone.utc).isoformat()

            rows_to_insert.append(row)

            # é€ä¿¡æ¡ä»¶ã¨ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‚’æ ¼ç´
            send_flg = row.get("send_flg", "").strip()
            email = row.get("email", "").strip()
            content = row.get("content", "").strip()
            if email and (send_flg == "1" or send_flg == "") and content:
                email_content_map[email] = content

    # BigQuery ã«ä¿å­˜
    errors = bq_client.insert_rows_json(table_ref, rows_to_insert)
    if errors:
        print(f"âŒ BigQueryæŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
    else:
        print(f"âœ… BigQueryã« {len(rows_to_insert)} ä»¶ã‚’æ›¸ãè¾¼ã¿å®Œäº†ã€‚")

        # ãƒ¡ãƒ¼ãƒ«é€ä¿¡ï¼ˆå€‹åˆ¥ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä»˜ãï¼‰
        for email, content in email_content_map.items():
            send_email(
                to_email=email,
                subject="CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†é€šçŸ¥",
                content=content
            )
